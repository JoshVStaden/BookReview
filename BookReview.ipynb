{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eHGm8RQlK46m"
   },
   "source": [
    "# Get and explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-erlYw1jXtgh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "goZIhX8nII4T"
   },
   "outputs": [],
   "source": [
    "# Make results reproducible - set random seed\n",
    "from numpy.random import seed\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_fEysQHII4W",
    "tags": []
   },
   "outputs": [],
   "source": [
    "negative_file = \"negative.txt\"\n",
    "positive_file = \"positive.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rWm4yycII4Y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not modify - helper function to load and preprocess data\n",
    "def filter_words(line):    \n",
    "    line = re.sub(r'[^\\w\\s]','',line.rstrip())\n",
    "    words = line.split(\" \") \n",
    "    words = [i.lower() for i in words if i]      \n",
    "    return \" \".join(words)\n",
    "\n",
    "def load_data(filename):\n",
    "    thefile = open(filename, 'r') \n",
    "    lines = thefile.readlines() \n",
    "\n",
    "    data = []\n",
    "    for l in range(0,len(lines)): \n",
    "        if(lines[l-1].strip() == \"<title>\"): \n",
    "            theline = filter_words(lines[l])\n",
    "            if(len(theline) < 50):\n",
    "                data.append(theline)            \n",
    "            \n",
    "    return data\n",
    "\n",
    "# Helper function to convert categorical data to class label\n",
    "def to_word_label(y):\n",
    "    y = to_class(y)   \n",
    "    return [\"positive\" if i==0 else \"negative\" for i in y]\n",
    "\n",
    "# Helper function to convert class label to numeric label\n",
    "def to_numeric_label(y):\n",
    "  return [0 if i==\"positive\" else 1 for i in word_labels]\n",
    "\n",
    "# Helper function: this function needs to be called before sending arrays to sklearn metrics,\n",
    "# it converts back to class form from categorical form. ie: [1,0] --> 0, [0,1] --> 1\n",
    "def to_class(y):\n",
    "    return np.argmax(y,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "jjGUiFm9II4b",
    "outputId": "aa5eb89b-85f2-4d61-f33a-b00361b19a41",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one of the best crichton novels', 'the medicine of the future', 'beautiful', 'for lovers of robicheaux', 'a good book', 'to the point and beautifully illustrated', 'at least somebody has got it', 'beautifully written heartwarming story', 'an excellent cookbook full of delicious recipes', 'an outstanding resource']\n",
      "['horrible book horrible', 'shallow selfindulgence', 'horrible book horrible', 'disappointment', 'a disappointing mess', 'save your money there are better books out there', 'thank you but no thanks', 'unendurable', 'the hard way', 'some good info among the political commercial']\n"
     ]
    }
   ],
   "source": [
    "positive = load_data(positive_file)\n",
    "negative = load_data(negative_file)\n",
    "\n",
    "print(positive[0:10])\n",
    "print(negative[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yrgEYOOCII4d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not modify - Combines the positive and negative reviews into a single list and create labels\n",
    "data = positive + negative\n",
    "word_labels = [\"positive\"] * len(positive) + [\"negative\"] * len(negative) \n",
    "\n",
    "# Converts labels to numbers in one-hot encoding - [1, 0] (positive) or [0, 1] (negative)\n",
    "from keras.utils import to_categorical\n",
    "labels  = to_categorical(to_numeric_label(word_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97Uh2uBpII4l",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write some code to investigate the dataset. \n",
    "# - Calculate and report the mean review size, its standard deviation and create a boxplot.\n",
    "# - Calculate the number of words in the dataset\n",
    "# - Perform any other dataset investigation that you feel would be valuable\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "_XXnArgcII4i",
    "outputId": "020b2ee2-4c2a-4bc0-bb55-e2ae3841fe57",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one of the best crichton novels', 'the medicine of the future', 'beautiful', 'for lovers of robicheaux', 'a good book']\n",
      "[[18, 4, 2, 19], [2, 4, 2], [], [6, 4], [1, 12, 3]]\n"
     ]
    }
   ],
   "source": [
    "# Do not modify - Tokenize the vocabulary \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=25)\n",
    "\n",
    "tokenizer.fit_on_texts(data) #create the vocabularry\n",
    "\n",
    "tokenized_data = tokenizer.texts_to_sequences(data) #tokenize the data using the vocabulary\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "\n",
    "# Compare a sample of the data before and after tokenization\n",
    "print(data[0:5])\n",
    "print(tokenized_data[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vsMmLjdK1Gf"
   },
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "24DaXd1zII4q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "# Write some code to pre-process the data so that each review is the same length\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "padded_tokenized_data = pad_sequences(tokenized_data, maxlen=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFTJcFy6II4s",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write some code to split the data into a training and test set. Make sure you shuffle the data. Use 20% for the test set.\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_tokenized_data, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "lDth1BSzII4u",
    "outputId": "4614049a-7151-4407-9bc8-54604bbe7fdd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Fill in the following function so it\n",
    "# - makes a prediction for the test set given the model\n",
    "# - reports the precision, recall and f1 score. Also print the confusion matrix. \n",
    "# You will need to use the helper to_class function to convert y_pred and y_test before supplying them to the sklearn functions.\n",
    "\n",
    "def assess_model(model, X_test, y_test):\n",
    "    y_class_test = to_class(y_test)\n",
    "    y_pred = to_class(model.predict(X_test))\n",
    "    precision = precision_score(y_class_test, y_pred)\n",
    "    recall = recall_score(y_class_test, y_pred)\n",
    "    f1 = f1_score(y_class_test, y_pred)\n",
    "    print(\"------------\")\n",
    "    print(\"Precision : \", precision)\n",
    "    print(\"Recall : \", recall)\n",
    "    print(\"F1 Score : \", f1)\n",
    "    print(\"Confusion Matrix : \", confusion_matrix(y_class_test, y_pred))\n",
    "    return precision, recall, f1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nTqLbbE6MpGt"
   },
   "source": [
    "# Build and tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3X70rA4uMXNv"
   },
   "source": [
    "Define network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wKoXWKG4II5F"
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, SpatialDropout1D, BatchNormalization, LSTM, Dense\n",
    "\n",
    "def build_model(od, b, no_epochs):\n",
    "    embedding_layer = Embedding(vocab_size, od, input_length=25)\n",
    "    dropout_layer = SpatialDropout1D(0.2)\n",
    "    norm_layer = BatchNormalization()\n",
    "    lstm_layer = LSTM(32)\n",
    "    output_layer = Dense(2, activation='softmax')\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(dropout_layer)\n",
    "    model.add(norm_layer)\n",
    "    model.add(lstm_layer)\n",
    "    model.add(output_layer)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, batch_size=b, epochs=no_epochs)\n",
    "    \n",
    "    return model, history, assess_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llS0-VKBMbz-"
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F5IJs0QuMe_I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6885 - accuracy: 0.5425\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6624 - accuracy: 0.6011\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6565 - accuracy: 0.5921\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6476 - accuracy: 0.6192\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6439 - accuracy: 0.6283\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.6390 - accuracy: 0.6241\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6403 - accuracy: 0.6158\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6290 - accuracy: 0.6290\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6347 - accuracy: 0.6220\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6347 - accuracy: 0.6241\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6260 - accuracy: 0.6269\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6233 - accuracy: 0.6234\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6247 - accuracy: 0.6346\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6225 - accuracy: 0.6255\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6171 - accuracy: 0.6409\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6161 - accuracy: 0.6471\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6171 - accuracy: 0.6290\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6115 - accuracy: 0.6437\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6059 - accuracy: 0.6437\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6050 - accuracy: 0.6520\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5996 - accuracy: 0.6527\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6054 - accuracy: 0.6388\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6006 - accuracy: 0.6492\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5970 - accuracy: 0.6506\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5991 - accuracy: 0.6478\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5974 - accuracy: 0.6499\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5921 - accuracy: 0.6506\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.5927 - accuracy: 0.6541\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6025 - accuracy: 0.6450\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5948 - accuracy: 0.6485\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5893 - accuracy: 0.6520\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5861 - accuracy: 0.6646\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.5932 - accuracy: 0.6604\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5890 - accuracy: 0.6534\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5874 - accuracy: 0.6618\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5841 - accuracy: 0.6667\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5812 - accuracy: 0.6562\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5798 - accuracy: 0.6639\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5824 - accuracy: 0.6674\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5839 - accuracy: 0.6576\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.5808 - accuracy: 0.6625\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5776 - accuracy: 0.6688\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5799 - accuracy: 0.6548\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.5786 - accuracy: 0.6667\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5707 - accuracy: 0.6674\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5662 - accuracy: 0.6688\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5676 - accuracy: 0.6702\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5743 - accuracy: 0.6771\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5702 - accuracy: 0.6715\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5628 - accuracy: 0.6722\n",
      "------------\n",
      "Precision :  0.6017699115044248\n",
      "Recall :  0.7431693989071039\n",
      "F1 Score :  0.665036674816626\n",
      "Confusion Matrix :  [[ 86  90]\n",
      " [ 47 136]]\n",
      "Epoch 1/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6911 - accuracy: 0.5167\n",
      "Epoch 2/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6656 - accuracy: 0.5941\n",
      "Epoch 3/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6536 - accuracy: 0.5976\n",
      "Epoch 4/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6541 - accuracy: 0.6067\n",
      "Epoch 5/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6435 - accuracy: 0.6290\n",
      "Epoch 6/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6417 - accuracy: 0.6158\n",
      "Epoch 7/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6402 - accuracy: 0.6206\n",
      "Epoch 8/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6346 - accuracy: 0.6297\n",
      "Epoch 9/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6339 - accuracy: 0.6165\n",
      "Epoch 10/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6329 - accuracy: 0.6206\n",
      "Epoch 11/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6287 - accuracy: 0.6437\n",
      "Epoch 12/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6229 - accuracy: 0.6374\n",
      "Epoch 13/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6227 - accuracy: 0.6304\n",
      "Epoch 14/51\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.6235 - accuracy: 0.6276\n",
      "Epoch 15/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6162 - accuracy: 0.6346\n",
      "Epoch 16/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6238 - accuracy: 0.6360\n",
      "Epoch 17/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6166 - accuracy: 0.6450\n",
      "Epoch 18/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6154 - accuracy: 0.6353\n",
      "Epoch 19/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6126 - accuracy: 0.6416\n",
      "Epoch 20/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6150 - accuracy: 0.6318\n",
      "Epoch 21/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6063 - accuracy: 0.6381\n",
      "Epoch 22/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6107 - accuracy: 0.6374\n",
      "Epoch 23/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6110 - accuracy: 0.6478\n",
      "Epoch 24/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6075 - accuracy: 0.6423\n",
      "Epoch 25/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6023 - accuracy: 0.6478\n",
      "Epoch 26/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6023 - accuracy: 0.6492\n",
      "Epoch 27/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.6011 - accuracy: 0.6478\n",
      "Epoch 28/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5966 - accuracy: 0.6527\n",
      "Epoch 29/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5924 - accuracy: 0.6639\n",
      "Epoch 30/51\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.5912 - accuracy: 0.6541\n",
      "Epoch 31/51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5952 - accuracy: 0.6590\n",
      "Epoch 32/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5960 - accuracy: 0.6541\n",
      "Epoch 33/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5976 - accuracy: 0.6492\n",
      "Epoch 34/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5899 - accuracy: 0.6625\n",
      "Epoch 35/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5904 - accuracy: 0.6548\n",
      "Epoch 36/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5873 - accuracy: 0.6618\n",
      "Epoch 37/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5888 - accuracy: 0.6576\n",
      "Epoch 38/51\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.5834 - accuracy: 0.6695\n",
      "Epoch 39/51\n",
      "33/72 [============>.................] - ETA: 0s - loss: 0.5848 - accuracy: 0.6606"
     ]
    }
   ],
   "source": [
    "# Compile model and train\n",
    "\n",
    "output_dim_candidates = [10, 25, 50, 100]\n",
    "batch_size_candidates = [20, 40, 60]\n",
    "\n",
    "best_f1 = 0\n",
    "best_model = None\n",
    "best_history = None\n",
    "best_stats = None\n",
    "best_hyperparams = None\n",
    "for od in output_dim_candidates:\n",
    "    for batch_size in batch_size_candidates:\n",
    "        for epochs in range(50, 52):\n",
    "            model, history, (precision, recall, f1) = build_model(od, batch_size, epochs)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_model = model\n",
    "                best_history = history\n",
    "                best_stats = (precision, recall, f1)\n",
    "                best_hyperparams = (od, batch_size, epochs)\n",
    "best_outputdim, best_batch_size, best_epochs = best_hyperparams\n",
    "best_precision, best_recall, best_f1 = best_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rniBBEiyMRKD"
   },
   "source": [
    "Examine performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eBVogHg2II5T",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "output_dim:  50\n",
      "batch_size:  20\n",
      "# epochs:  6\n",
      "Best stats: \n",
      "precision:  0.5582191780821918\n",
      "recall:  0.8907103825136612\n",
      "f1 score:  0.6863157894736842\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters:\")\n",
    "print(\"output_dim: \", best_outputdim)\n",
    "print(\"batch_size: \", best_batch_size)\n",
    "print(\"# epochs: \", best_epochs)\n",
    "print(\"Best stats: \")\n",
    "print(\"precision: \", best_precision)\n",
    "print(\"recall: \", best_recall)\n",
    "print(\"f1 score: \", best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HB8kzt-IME4U"
   },
   "source": [
    "Plot graphs for accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPyJ78unMJUI"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(best_history.history['loss'], label='Loss')\n",
    "plt.plot(best_history.history['accuracy'], label='Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAZ1LyFBMLoK"
   },
   "source": [
    "# Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vfPM5LokII5V",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this book is fabulous  :  negative\n",
      "i hated this book  :  negative\n",
      "the best  :  negative\n",
      "no good  :  negative\n",
      "okay  :  negative\n"
     ]
    }
   ],
   "source": [
    "# This is a very small set of completed new data to use to make predictions.\n",
    "prediction_data = [\"this book is fabulous\",\"i hated this book\", \"the best\", \"no good\", \"okay\"]\n",
    "tokenized = tokenizer.texts_to_sequences(prediction_data)\n",
    "padded = pad_sequences(tokenized, padding='post', maxlen=25)\n",
    "\n",
    "# Supply this data to each of your models and see how it does. \n",
    "# You can call the helper function \"to_word_label\" to map the output of the model to the name of the\n",
    "# class it was predicted to belong to.\n",
    "y_pred = to_word_label(best_model.predict(padded))\n",
    "for i in range(len(y_pred)):\n",
    "    print(prediction_data[i], \" : \", y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "L3T20.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
